---
title: "DS311 Project Q2"
author: "Gabrielle Salamanca"
date: "March 17, 2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## We-R-Finished

Before we can dive into the question, we must load in the necessary libraries and read the dataset into the markdown.

```{r}
# loading libraries
library(readxl)
library(caret)
library(ggplot2)
library(dplyr)

# dataset overview
salary <- read_excel("C:/Users/knigh/OneDrive/Desktop/Github/We-R-Finished/salary/salary_data_states.xlsx")
```

Next, let's rename the columns to make it easier for us to read.

```{r}
# renaming
colnames(salary)[1] = "Case Number"
colnames(salary)[2] = "Case Status"
colnames(salary)[3] = "Received Date"
colnames(salary)[4] = "Decision Date"
colnames(salary)[5] = "Employer Name"
colnames(salary)[6] = "Submitted Prevail Wage"
colnames(salary)[7] = "SPrW Unit"
colnames(salary)[8] = "Submitted Paid Wage"
colnames(salary)[9] = "SPaW Unit"
colnames(salary)[10] = "Job Title"
colnames(salary)[11] = "Work City"
colnames(salary)[12] = "Required Edu"
colnames(salary)[13] = "Required College Major"
colnames(salary)[14] = "Exp Req"
colnames(salary)[15] = "Exp Req (Months)"
colnames(salary)[16] = "Citizenship"
colnames(salary)[17] = "Prevail Wage SOC Code"
colnames(salary)[18] = "PWSOC Title"
colnames(salary)[19] = "Work State"
colnames(salary)[20] = "WS Abb"
colnames(salary)[21] = "WPostal Code"
colnames(salary)[22] = "Full Time"
colnames(salary)[23] = "Visa Class"
colnames(salary)[24] = "Prevail Wage/Yr"
colnames(salary)[25] = "Paid Wage/Yr"
colnames(salary)[26] = "Job Title Sub"
colnames(salary)[27] = "Order"
```

Now, we must remove the sub job titles that have teaching jobs. The question specifically asks for data-related salaries in the job sub-categories, therefore we must remove: professor, attorney, assistant professor, and teacher.

```{r}
# filter
sal <- salary %>%
  filter(!grepl("professor", `Job Title Sub`, ignore.case = TRUE) & 
           !grepl("attorney", `Job Title Sub`, ignore.case = TRUE) &
           !grepl("assistant professor", `Job Title Sub`, ignore.case = TRUE) & 
           !grepl("teacher", `Job Title Sub`, ignore.case = TRUE))
jobTitleSub <- as.factor(sal$`Job Title Sub`)
summary(jobTitleSub)
```

### II. What states (of those I am willing to move to) have the highest paying data-related salaries?

This is quite a broad range of states, but we will remove any US territories first and foremost for obvious reasons. This means Guam, Guamam, Palau, Northern Mariana Islands, Puerto Rico, and Virgin Islands will not be considered. 

```{r}
# filtering states
datsal <- sal %>%
  filter(!grepl("Guam", `Work State`, ignore.case = TRUE) & 
           !grepl("Guamam", `Work State`, ignore.case = TRUE) &
           !grepl("Palau", `Work State`, ignore.case = TRUE) & 
           !grepl("Northern Mariana Islands", `Work State`, ignore.case = TRUE) &
           !grepl("Puerto Rico", `Work State`, ignore.case = TRUE) &
           !grepl("Virgin Islands", `Work State`, ignore.case = TRUE))
```

Now, that still leaves us with a large amount of states. When I tried running graphs to include work state and the job title sub variables, R had difficulty running them, because it was far too many to handle. 

Now, the question asks *"What states (of those I am willing to move to)"*. Considering the group is staying in the Bay Area, we may be more picky about where we would want to live. California is much more friendly towards immigrants and quite open to people of all walks of life. We may be biased to stay within the West Coast, especially considering the natural disasters and how certain minorities are treated here either by law or general perception. This would greatly narrow the scope, so I have decided to use the top 10 work states as my pool, minus California. My reasoning is because we are already in California, and the state has a frequency of:

```{r}
CAfreq <- table(datsal$`Work State`)["California"]
CAfreq
```

This state completely dwarfs the others. Consider Texas, it has a frequency of:

```{r}
TXfreq <- table(datsal$`Work State`)["Texas"]
TXfreq
```

This will greatly skew the graphs if there's a roughly 30,000 difference between these two, especially if the majority of the rest are only in the single digit 1000s.

```{r}
topState <- c("TX", "NY", "NJ", "IL", "MA", "VA", "PA", "WA","MI", "NC")
ssal <- datsal[datsal$`WS Abb` %in% topState, ]
```

#### a. Differences between job sub-categories?

```{r}
stateAbb <- ssal$`WS Abb`
jobSub <- ssal$`Job Title Sub`
# job sub/state plot
ggplot(ssal, aes(x = stateAbb, fill = jobSub)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Work State Abbreviation", y = "Count", title = "Job Subcategories in Each State")
# state/job sub
ggplot(ssal, aes(x = jobSub, fill = stateAbb)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Job Title Sub", y = "Count", title = "States for Each Job Subcategory")

```


#### b. Which companies have the highest salaries for those sub-types?

#### c. Will the answer change if I take standard of living into account?

```{r, ref.label=knitr::all_labels(), echo = TRUE, eval = FALSE}
```